{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "import datetime\n",
    "import lightgbm as lgb\n",
    "from scipy import stats\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import os\n",
    "#import xgboost as xgb\n",
    "#import lightgbm as lgb\n",
    "from functools import reduce\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "from math import sqrt\n",
    "from lightgbm import plot_tree\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "from hyperopt import Trials\n",
    "from hyperopt import fmin\n",
    "from hyperopt import STATUS_OK\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "import gc\n",
    "from sklearn.linear_model import LinearRegression\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2552"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('dataset-0510/train.csv')\n",
    "test  = pd.read_csv('dataset-0510/test.csv')\n",
    "data = pd.concat([train, test], axis=0)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_process(df):\n",
    "    \n",
    "    #target_encoding\n",
    "    temp_train = df[:60000]\n",
    "    combine_rows = ['city', 'town', 'building_type']\n",
    "    target_df = temp_train.groupby(combine_rows).agg({'building_area' : ['mean', 'median'], 'land_area' : ['mean', 'median'], 'total_price' : ['mean', 'median']}).reset_index()\n",
    "    target_df.columns = [i[0] + '_' + i[1]  if i[1] != '' else i[0] for i in target_df.columns.tolist()]\n",
    "    target_df['total_price_median'] = np.log1p(target_df['total_price_median'])\n",
    "    target_df['total_price_mean'] = np.log1p(target_df['total_price_mean'])\n",
    "    \n",
    "    target_df['price_land_rate_median'] = target_df['total_price_median'] / target_df['land_area_median']\n",
    "    target_df['price_building_rate_median'] = target_df['total_price_median'] / target_df['building_area_median']\n",
    "    target_df['price_land_rate_mean'] = target_df['total_price_mean'] / target_df['land_area_mean']\n",
    "    target_df['price_building_rate_mean'] = target_df['total_price_mean'] / target_df['building_area_mean']\n",
    "    \n",
    "    combine_cols = combine_rows + ['price_land_rate_median', 'price_building_rate_median', 'total_price_median']\n",
    "    df = pd.merge(df, target_df[combine_cols], on = combine_rows, how='left')\n",
    "    \n",
    "    df['min_cat'] = 0\n",
    "    for col in [i for i in df.columns if 'MIN' in i]:\n",
    "        df['min_cat'] = df.apply(lambda x : col if x['min_cat'] == x[col] else x['min_cat'], axis=1)  \n",
    "    \n",
    "    #10, 50, 100, 250, 500, 1000, 5000, 10000\n",
    "    for num in ['_10', '_50', '_100', '_250', '_500', '_1000', '_5000', '_10000']:\n",
    "        df['Mean_' + num] = df[[i for i in df.columns if i.endswith(num) and 'index' not in i and 'N' not in i]].apply(lambda x : x.mean(), axis=1)\n",
    "        df['Median_' + num] = df[[i for i in df.columns if i.endswith(num) and 'index' not in i and 'N' not in i]].apply(lambda x : x.median(), axis=1)\n",
    "        df['Std_' + num] = df[[i for i in df.columns if i.endswith(num) and 'index' not in i and 'N' not in i]].apply(lambda x : x.std(), axis=1)\n",
    "        df['Skew_' + num] = df[[i for i in df.columns if i.endswith(num) and 'index' not in i and 'N' not in i]].apply(lambda x : x.skew(), axis=1)\n",
    "\n",
    "    \n",
    "    #MIN\n",
    "    MIN_cols = [i for i in df.columns if '_MIN' in i]\n",
    "    df[MIN_cols].apply(lambda x : x.mean(), axis =1 )\n",
    "    df[MIN_cols].apply(lambda x : x.median(), axis =1 )\n",
    "    df[MIN_cols].apply(lambda x : x.std(), axis =1 )\n",
    "    df[MIN_cols].apply(lambda x : x.skew(), axis =1 )\n",
    "    \n",
    "    rank_df = df[MIN_cols].rank(axis =1)\n",
    "    rank_df = rank_df.add_prefix('Rank_')\n",
    "    df = pd.concat([df, rank_df], axis=1)\n",
    "    \n",
    "    #parking\n",
    "    df['price_area'] = 1\n",
    "    df.loc[df['parking_price'].notna(), 'price_area'] = 2\n",
    "    df.loc[df['parking_area'].notna(), 'price_area'] = 3\n",
    "    \n",
    "    df.loc[df['parking_way'] == 2, 'parking_area'] = 0\n",
    "    df.loc[df['parking_way'] == 2, 'parking_price'] = 0\n",
    "    \n",
    "    df = pd.concat([df, pd.get_dummies(df['price_area'], prefix='price_area')], axis=1)\n",
    "    #Impute missing value\n",
    "    df['village_income_mean'] = df.groupby(['city', 'town'])['village_income_median'].transform(lambda x : x .fillna(x.mean()))\n",
    "    \n",
    "    #location\n",
    "\n",
    "    df['location_2'] = df.apply(lambda x : int(str(x['city']) + str(x['town'])), axis=1)\n",
    "    df['city'] = df['city'].astype('category')\n",
    "    df['location_2'] = df['location_2'].astype('category')\n",
    "    \n",
    "    '''\n",
    "    #degree rate\n",
    "    df['diff_doc_master'] = df['doc_rate'] - df['master_rate']\n",
    "    df['diff_master_bachelor'] = df['master_rate'] - df['bachelor_rate']\n",
    "    df['diff_bachelor_highsch'] = df['bachelor_rate'] - df['highschool_rate']\n",
    "    df['diff_highsch_jobschool'] = df['highschool_rate'] - df['jobschool_rate']\n",
    "    df['diff_jobschool_elesch'] = df['jobschool_rate'] - df['elementary_rate']\n",
    "    \n",
    "    df['all_degree'] = df['doc_rate'] + df['master_rate'] + df['bachelor_rate'] + df['highschool_rate'] + df['jobschool_rate'] + df['junior_rate'] + df['elementary_rate']\n",
    "    df['junior_above_rate'] = df['doc_rate'] + df['master_rate'] + df['bachelor_rate'] + df['highschool_rate'] + df['jobschool_rate'] + df['junior_rate'] \n",
    "    df['jobschool_above_rate'] = df['doc_rate'] + df['master_rate'] + df['bachelor_rate'] + df['highschool_rate'] +  df['jobschool_rate']\n",
    "    df['highschool_above_rate'] = df['doc_rate'] + df['master_rate'] + df['bachelor_rate'] + df['highschool_rate']\n",
    "    df['bachelor_above_rate'] = df['doc_rate'] + df['master_rate'] + df['bachelor_rate']\n",
    "    df['master_above_rate'] = df['doc_rate'] + df['master_rate'] \n",
    "    '''\n",
    "    \n",
    "    #building\n",
    "    df['building_use'] = df['building_use'].astype('category')\n",
    "    df['building_material'] = df['building_material'].astype('category')\n",
    "    \n",
    "    #floor\n",
    "    df.loc[df['txn_floor'].isna(), 'department'] = 1 \n",
    "    df.loc[df['txn_floor'].notna(), 'department'] = 0\n",
    "    df['avg_height_floor'] = df['txn_floor'] / df['total_floor'] \n",
    "    df['avg_height_floor'].fillna(0, inplace = True)\n",
    "    \n",
    "    #area\n",
    "    df['land/bulid_area'] = df['land_area'] / df ['building_area']\n",
    "    df['parking_rate'] = df['building_area'] / df['parking_area']\n",
    "    \n",
    "    #date\n",
    "    df['day_between_txn_complete'] = df['txn_dt'] - df['building_complete_dt']\n",
    "    df['year_between_txn_complete'] = round(df['day_between_txn_complete'] / 365)\n",
    "    \n",
    "    #soical rate\n",
    "    '''\n",
    "    df['natural_diff'] = df['born_rate'] - df['death_rate']\n",
    "    df['natural_rate'] = df['born_rate'] / df['death_rate']\n",
    "    \n",
    "    df['marry_diff'] = df['marriage_rate'] - df['divorce_rate']\n",
    "    df['marry_rate'] = df['marriage_rate'] / df['divorce_rate']\n",
    "    \n",
    "    df['total_diff_sum'] = df['natural_rate'] + df['marry_diff']\n",
    "    df['total_diff_diff'] = df['natural_rate'] - df['marry_diff']\n",
    "    df['total_rate_diff'] = df['born_rate'] + df['marry_rate']\n",
    "    \n",
    "    df['positive_grow_rate'] = df['born_rate'] + df['marriage_rate']\n",
    "    df['negative_grow_rate'] = df['death_rate'] + df['divorce_rate']\n",
    "    df['tatal_rate_sum'] = df['born_rate'] + df['death_rate'] + df['born_rate'] + df['death_rate']\n",
    "    '''\n",
    "    \n",
    "    #village_income_median\n",
    "    temp = df.groupby(['city', 'town', 'village'])['village_income_median'].first().reset_index()\n",
    "    temp = df.groupby(['city', 'town']).agg({'village_income_median' : ['mean', 'sum', 'median']})\n",
    "    temp = temp.rename({'village_income_median' : 'town_income_median'}, level = 0)\n",
    "    temp.columns = [e[0] + '_' + e[1] if e[1] != '' else e[0] for e in temp.columns.tolist()]\n",
    "    df = pd.merge(df, temp, on = ['city', 'town'], how = 'left')\n",
    "\n",
    "    temp = df.groupby(['city', 'town', 'village'])['village_income_median'].first().reset_index()\n",
    "    temp = df.groupby(['city']).agg({'village_income_median' : ['mean', 'sum', 'median']})\n",
    "    temp = temp.rename({'village_income_median' : 'city_income_median'}, level = 0)\n",
    "    temp.columns = [e[0] + '_' + e[1] if e[1] != '' else e[0] for e in temp.columns.tolist()]\n",
    "    df = pd.merge(df, temp, on = ['city'], how = 'left')\n",
    "    \n",
    "    #Build_case\n",
    "    cols = ['city', 'town', 'village', 'building_type', 'building_use', 'total_floor', 'XIV_MIN', 'building_complete_dt']\n",
    "    df.loc[df[cols].duplicated(keep = False), 'Build_case'] = 0\n",
    "    df.loc[~df[cols].duplicated(keep = False), 'Build_case'] = 1\n",
    "    \n",
    "    #interection \n",
    "    '''\n",
    "    locations =['city', 'location2']\n",
    "    inter_cols = ['building_type', 'building_use', 'building_material']\n",
    "    for location in locations:\n",
    "        for inter_col in inter_cols:\n",
    "            df['inter_btw_' + location +'_' + inter_col] = df.apply(lambda x : str(x[location]) + str(x[inter_col]), axis=1)\n",
    "            df['inter_btw_' + location +'_' + inter_col] = df['inter_btw_' + location +'_' + inter_col].astype('category')\n",
    "    '''\n",
    "    inter_cols = ['building_type', 'building_use', 'building_material', 'parking_way']\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            if j > i:\n",
    "                df['inter_btw_' + inter_cols[i] +'_' + inter_cols[j]] = df.apply(lambda x : str(x[inter_cols[i]]) + str(x[inter_cols[j]]), axis=1)\n",
    "                df['inter_btw_' + inter_cols[i] +'_' + inter_cols[j]] = df['inter_btw_' + inter_cols[i] +'_' + inter_cols[j]].astype('category')\n",
    "    #one-hot\n",
    "    df = df.join(pd.get_dummies(df['parking_way'], prefix = 'parking_way'))\n",
    "    df = df.join(pd.get_dummies(df['building_type'], prefix = 'building_type'))\n",
    "    df = df.join(pd.get_dummies(df['building_material'], prefix = 'building_material'))\n",
    "    df = df.join(pd.get_dummies(df['building_use'], prefix = 'building_use'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #useless cols\n",
    "    df.drop(['village', 'town', 'building_type', 'parking_way','building_material', 'building_use'], axis = 1, inplace = True)\n",
    "    df.drop([i for i in train.columns if np.sum(train[i]) == 60000 and 'index' in i], axis = 1, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 309)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = feature_process(data)\n",
    "FE_train = final_data[:60000]\n",
    "FE_test = final_data[60000:]\n",
    "FE_train.to_csv('FE_train.csv', index = False)\n",
    "FE_test.to_csv('FE_test.csv', index = False)\n",
    "len(FE_train.columns), len(FE_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60000 entries, 0 to 59999\n",
      "Columns: 309 entries, III_10 to building_use_10\n",
      "dtypes: category(7), float64(99), int64(172), object(1), uint8(30)\n",
      "memory usage: 127.2+ MB\n"
     ]
    }
   ],
   "source": [
    "FE_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price_area_1',\n",
       " 'price_area_2',\n",
       " 'price_area_3',\n",
       " 'location_2',\n",
       " 'inter_btw_building_type_building_use',\n",
       " 'inter_btw_building_type_building_material',\n",
       " 'inter_btw_building_type_parking_way',\n",
       " 'inter_btw_building_use_building_material',\n",
       " 'inter_btw_building_use_parking_way',\n",
       " 'inter_btw_building_material_parking_way',\n",
       " 'parking_way_0',\n",
       " 'parking_way_1',\n",
       " 'parking_way_2',\n",
       " 'building_type_0',\n",
       " 'building_type_1',\n",
       " 'building_type_2',\n",
       " 'building_type_3',\n",
       " 'building_type_4',\n",
       " 'building_material_1',\n",
       " 'building_material_3',\n",
       " 'building_material_4',\n",
       " 'building_material_5',\n",
       " 'building_material_7',\n",
       " 'building_material_8',\n",
       " 'building_material_9',\n",
       " 'building_material_10',\n",
       " 'building_material_11',\n",
       " 'building_use_0',\n",
       " 'building_use_1',\n",
       " 'building_use_2',\n",
       " 'building_use_3',\n",
       " 'building_use_4',\n",
       " 'building_use_5',\n",
       " 'building_use_6',\n",
       " 'building_use_7',\n",
       " 'building_use_8',\n",
       " 'building_use_10']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in FE_train.columns if FE_train[i].dtypes not in ['float64', 'int64', 'O']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['temp'] = ''\n",
    "for col in [i for i in train.columns if i.endswith('index_500')]:\n",
    "    train['temp'] = train['temp']+ train[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11111111111111    17244\n",
       "11101111111111    10113\n",
       "11101011111111     5695\n",
       "11111011111111     5180\n",
       "11101011111101     2706\n",
       "11101111111101     2491\n",
       "11111111111101     2316\n",
       "11111011111101     1558\n",
       "01101011111111      532\n",
       "01101011111101      506\n",
       "11101011110101      498\n",
       "01111111111111      335\n",
       "01111011111111      308\n",
       "11101111110101      297\n",
       "11101011110111      292\n",
       "01101111111111      280\n",
       "01101111111101      235\n",
       "11101111110111      233\n",
       "11101011011101      229\n",
       "11111011110101      211\n",
       "11101011011111      210\n",
       "11111111110101      189\n",
       "11101011101101      181\n",
       "01111011111101      177\n",
       "11101011100101      128\n",
       "11111111110111      123\n",
       "11101011000101      122\n",
       "11111011110111      120\n",
       "10101011111101      117\n",
       "00000000000101      108\n",
       "                  ...  \n",
       "11000011011111        1\n",
       "10001010110111        1\n",
       "00101001010101        1\n",
       "01100001111101        1\n",
       "00000000001100        1\n",
       "01000010010001        1\n",
       "10111111110111        1\n",
       "00010000000100        1\n",
       "11011011010111        1\n",
       "01001001001111        1\n",
       "11010110010101        1\n",
       "11110011000100        1\n",
       "01101010101101        1\n",
       "11110111111101        1\n",
       "11001010001011        1\n",
       "10111111101101        1\n",
       "11101011111110        1\n",
       "01111111100101        1\n",
       "01110011001101        1\n",
       "01001001010101        1\n",
       "11011011011111        1\n",
       "10111011101101        1\n",
       "01100110001111        1\n",
       "01010010001100        1\n",
       "01111110011111        1\n",
       "01101010001101        1\n",
       "11110010010101        1\n",
       "10111110011101        1\n",
       "10000101010101        1\n",
       "01000110001101        1\n",
       "Name: temp, Length: 879, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['temp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['I_10','I_50','I_100','I_250','I_500','I_1000','I_5000','I_10000']:\n",
    "    train[i + '_average'] = train[i] / int(i.split('_')[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: I_10_average, dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['I_10_average'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: I_50_average, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['I_50_average'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.01\n",
       "1    0.01\n",
       "2    0.01\n",
       "3    0.00\n",
       "4    0.00\n",
       "Name: I_100_average, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['I_100_average'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.020\n",
       "1    0.008\n",
       "2    0.004\n",
       "3    0.000\n",
       "4    0.000\n",
       "Name: I_250_average, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['I_250_average'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.040\n",
       "1    0.010\n",
       "2    0.016\n",
       "3    0.000\n",
       "4    0.000\n",
       "Name: I_500_average, dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['I_500_average'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.059\n",
       "1    0.013\n",
       "2    0.039\n",
       "3    0.009\n",
       "4    0.001\n",
       "Name: I_1000_average, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['I_1000_average'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
