{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "import lightgbm as lgb\n",
    "from scipy import stats\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stop = set(stopwords.words('english'))\n",
    "import os\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "import json\n",
    "import ast\n",
    "import eli5\n",
    "from functools import reduce\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "from math import sqrt\n",
    "from lightgbm import plot_tree\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "from hyperopt import Trials\n",
    "from hyperopt import fmin\n",
    "from hyperopt import STATUS_OK\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "import time\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "#import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset-0510/train.csv')\n",
    "test  = pd.read_csv('dataset-0510/test.csv')\n",
    "data = pd.concat([train, test], axis=0)\n",
    "#train.drop(['village'], axis =1, inplace = True)\n",
    "#test.drop(['village'], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Submission(Ids, preds):\n",
    "    file_name = datetime.datetime.today().strftime('%m-%d-%H-%M')\n",
    "    submission = pd.DataFrame({'building_id' : Ids, 'total_price' : preds})\n",
    "    if not os.path.isdir('Submission'):\n",
    "        os.makedirs('Submission')\n",
    "    submission.to_csv('Submission/' + file_name + '.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_importances(feature_importance_df):\n",
    "    cols = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-9e22816c69d6>, line 51)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-9e22816c69d6>\"\u001b[0;36m, line \u001b[0;32m51\u001b[0m\n\u001b[0;31m    cat_features = category_cols\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def cat_model(split_num, train, test,features, stratified = False, if_one_hot = True):\n",
    "    '''\n",
    "    category_cols = ['building_material',\n",
    " 'building_type',\n",
    " 'building_use',\n",
    " 'parking_way',\n",
    " 'location_2',\n",
    " 'inter_btw_building_type_parking_way',\n",
    " 'inter_btw_building_type_building_use',\n",
    " 'inter_btw_building_type_building_material',\n",
    " 'inter_btw_parking_way_building_use',\n",
    " 'inter_btw_parking_way_building_material',\n",
    " 'inter_btw_building_use_building_material']\n",
    "    '''\n",
    "    category_cols = ['building_material','building_use','parking_way', 'city']\n",
    "    \n",
    "    if stratified:\n",
    "        kf = StratifiedKFold(n_splits = split_num, random_state = 42, shuffle = True)\n",
    "    else :\n",
    "        kf = KFold(n_splits = split_num, random_state=42, shuffle=True)\n",
    "    train['total_price_log'] = np.log1p(train['total_price'])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    oof = np.zeros(len(train))\n",
    "    predictions = np.zeros(len(test))\n",
    "    \n",
    "    param ={\n",
    "        'n_estimators': 10000, 'max_depth' : -1, 'num_leaves' :30,         \n",
    "        'objective': 'regression',   'metric':'rmse',   \n",
    "        'learning_rate': 0.01,      'boosting': 'gbdt',     'min_data_in_leaf': 10,\n",
    "        'feature_fraction': 0.9,    'bagging_freq':1,       'bagging_fraction': 0.8,     'importance_type': 'gain',\n",
    "        'lambda_l1': 0.2,  'subsample': .8,   'colsample_bytree': .9\n",
    "    }\n",
    "\n",
    "    features = [i for i in train.columns if i not in ['building_id', 'total_price','total_price_log']] \n",
    "     \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(kf.split(train[features].values,train['total_price_log'].values)):\n",
    "        train_x = train.iloc[trn_idx][features]\n",
    "        train_y = train['total_price_log'].iloc[trn_idx]\n",
    "        val_x = train.iloc[val_idx][features]\n",
    "        val_y = train['total_price_log'].iloc[val_idx]\n",
    "        \n",
    "        clf = CatBoostRegressor(iterations=100000,\n",
    "                                 learning_rate=0.004,\n",
    "                                 depth=5,\n",
    "                                 eval_metric='RMSE',\n",
    "                                 colsample_bylevel=0.8,\n",
    "                                 random_seed = 42,\n",
    "                                 bagging_temperature = 0.2,\n",
    "                                 metric_period = None,\n",
    "                                 early_stopping_rounds=200\n",
    "                                 cat_features = category_cols\n",
    "                                )\n",
    "        clf.fit(train_x, train_y,\n",
    "                 eval_set=(val_x, val_y),\n",
    "                 use_best_model=True,\n",
    "                 verbose=1000)\n",
    "        oof[val_idx] = clf.predict(train.iloc[val_idx][features])\n",
    "        predictions += clf.predict(test[features], num_iteration = clf.best_iteration) / kf.n_splits\n",
    "        \n",
    "        y   = np.expm1(train['total_price_log'].iloc[val_idx]) \n",
    "        yhat = np.expm1(oof[val_idx])\n",
    "        Hit_score = np.sum([1 for i in np.abs((y - yhat) / y)  if i <= 0.1 ])\n",
    "        print('fold {} hit_score : {}'.format(fold_ + 1, round(Hit_score, 4) /len(train.iloc[val_idx]) * 10000))\n",
    "        print('-'*30)\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df['feature']    = features\n",
    "        fold_importance_df['importance'] = np.log1p(clf.feature_importance(importance_type='gain', iteration=clf.best_iteration))\n",
    "        fold_importance_df['fold']       = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    print('CV scrore : {}'.format(sqrt(mean_squared_error(train['total_price_log'], oof))))\n",
    "    print('-'*30)\n",
    "    y = np.expm1(train['total_price_log']) \n",
    "    yhat = np.expm1(oof)\n",
    "    Hit_score = np.sum([1 for i in np.abs((y - yhat) / y)  if i <= 0.1 ])\n",
    "    print('Hit rate : {}'.format(round(Hit_score, 4) /len(train) * 10000))\n",
    "    \n",
    "    display_importances(feature_importance_df)\n",
    "    return predictions, round(Hit_score, 4) /len(train) * 10000, oof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(split_num, train, test,features, stratified = False, if_one_hot = True):\n",
    "    '''\n",
    "    category_cols = ['building_material',\n",
    " 'building_type',\n",
    " 'building_use',\n",
    " 'parking_way',\n",
    " 'location_2',\n",
    " 'inter_btw_building_type_parking_way',\n",
    " 'inter_btw_building_type_building_use',\n",
    " 'inter_btw_building_type_building_material',\n",
    " 'inter_btw_parking_way_building_use',\n",
    " 'inter_btw_parking_way_building_material',\n",
    " 'inter_btw_building_use_building_material']\n",
    "    '''\n",
    "    category_cols = ['building_material','building_use','parking_way', 'city']\n",
    "    \n",
    "    if stratified:\n",
    "        kf = StratifiedKFold(n_splits = split_num, random_state = 42, shuffle = True)\n",
    "    else :\n",
    "        kf = KFold(n_splits = split_num, random_state=42, shuffle=True)\n",
    "    train['total_price_log'] = np.log1p(train['total_price'])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    oof = np.zeros(len(train))\n",
    "    predictions = np.zeros(len(test))\n",
    "    \n",
    "    param ={\n",
    "        'n_estimators': 10000, 'max_depth' : -1, 'num_leaves' :30,         \n",
    "        'objective': 'regression',   'metric':'rmse',   \n",
    "        'learning_rate': 0.01,      'boosting': 'gbdt',     'min_data_in_leaf': 10,\n",
    "        'feature_fraction': 0.9,    'bagging_freq':1,       'bagging_fraction': 0.8,     'importance_type': 'gain',\n",
    "        'lambda_l1': 0.2,  'subsample': .8,   'colsample_bytree': .9\n",
    "    }\n",
    "\n",
    "    features = [i for i in train.columns if i not in ['building_id', 'total_price','total_price_log']] \n",
    "     \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(kf.split(train[features].values,train['total_price_log'].values)):\n",
    "        trn_data = lgb.Dataset(train.iloc[trn_idx][features], label= train['total_price_log'].iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(train.iloc[val_idx][features], label= train['total_price_log'].iloc[val_idx])\n",
    "        \n",
    "        \n",
    "        clf = lgb.train(params= param, train_set= trn_data, valid_sets= [trn_data, val_data], verbose_eval=1000, early_stopping_rounds= 10000)\n",
    "        oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration = clf.best_iteration)\n",
    "        predictions += clf.predict(test[features], num_iteration = clf.best_iteration) / kf.n_splits\n",
    "        \n",
    "        y   = np.expm1(train['total_price_log'].iloc[val_idx]) \n",
    "        yhat = np.expm1(oof[val_idx])\n",
    "        Hit_score = np.sum([1 for i in np.abs((y - yhat) / y)  if i <= 0.1 ])\n",
    "        print('fold {} hit_score : {}'.format(fold_ + 1, round(Hit_score, 4) /len(train.iloc[val_idx]) * 10000))\n",
    "        print('-'*30)\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df['feature']    = features\n",
    "        fold_importance_df['importance'] = np.log1p(clf.feature_importance(importance_type='gain')\n",
    "        fold_importance_df['fold']       = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    print('CV scrore : {}'.format(sqrt(mean_squared_error(train['total_price_log'], oof))))\n",
    "    print('-'*30)\n",
    "    y = np.expm1(train['total_price_log']) \n",
    "    yhat = np.expm1(oof)\n",
    "    Hit_score = np.sum([1 for i in np.abs((y - yhat) / y)  if i <= 0.1 ])\n",
    "    print('Hit rate : {}'.format(round(Hit_score, 4) /len(train) * 10000))\n",
    "    \n",
    "    display_importances(feature_importance_df)\n",
    "    return predictions, round(Hit_score, 4) /len(train) * 10000, oof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10000 rounds.\n",
      "[10000]\ttraining's rmse: 0.0277108\tvalid_1's rmse: 0.177004\n",
      "[20000]\ttraining's rmse: 0.0142966\tvalid_1's rmse: 0.176804\n",
      "Early stopping, best iteration is:\n",
      "[18626]\ttraining's rmse: 0.0152364\tvalid_1's rmse: 0.176792\n",
      "fold 1 hit_score : 5853.889943074004\n",
      "------------------------------\n",
      "Training until validation scores don't improve for 10000 rounds.\n",
      "[10000]\ttraining's rmse: 0.0281996\tvalid_1's rmse: 0.190081\n",
      "Early stopping, best iteration is:\n",
      "[9703]\ttraining's rmse: 0.0290402\tvalid_1's rmse: 0.190076\n",
      "fold 2 hit_score : 5666.824869482677\n",
      "------------------------------\n",
      "Training until validation scores don't improve for 10000 rounds.\n",
      "[10000]\ttraining's rmse: 0.0285357\tvalid_1's rmse: 0.203201\n",
      "[20000]\ttraining's rmse: 0.0148275\tvalid_1's rmse: 0.203202\n",
      "Early stopping, best iteration is:\n",
      "[11634]\ttraining's rmse: 0.0246648\tvalid_1's rmse: 0.203121\n",
      "fold 3 hit_score : 5723.777883246322\n",
      "------------------------------\n",
      "Training until validation scores don't improve for 10000 rounds.\n",
      "[10000]\ttraining's rmse: 0.0284842\tvalid_1's rmse: 0.187846\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bce1600ae000>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtemp_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'building_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtemp_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'building_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhit_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mif_one_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'building_id'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtemp_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'building_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'total_price'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprediction_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-0c8020f53bc1>\u001b[0m in \u001b[0;36mlgb_model\u001b[0;34m(split_num, train, test, features, stratified, if_one_hot)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrn_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrn_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategory_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0moof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    214\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1758\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1760\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1761\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "avg_hit_rate = 0\n",
    "prediction_df = pd.DataFrame()\n",
    "hit_score_list = []\n",
    "train_num_list = []\n",
    "building_df_list   = []\n",
    "oof_list       = []\n",
    "features = [i for i in train.columns if i not in ['building_id', 'total_price','total_price_log','city']] \n",
    "for b_type in train['building_type'].unique():\n",
    "    temp_train = train[train['building_type'] == b_type]\n",
    "    temp_test  = test[test['building_type'] == b_type]\n",
    "    temp_train.drop(['building_type'], axis =1, inplace =True)\n",
    "    temp_test.drop(['building_type'], axis =1, inplace =True)\n",
    "    preds, hit_score, oof = lgb_model(5, temp_train, temp_test, features= features,if_one_hot=False)\n",
    "    temp = pd.DataFrame({'building_id' : temp_test['building_id'], 'total_price' : preds})\n",
    "    prediction_df = pd.concat([prediction_df, temp], axis=0)\n",
    "    \n",
    "    print('building_type : {}'.format(b_type))\n",
    "    print('Train_num: {}'.format(len(temp_train)))\n",
    "    print('Test_num: {}'.format(len(temp_test)))\n",
    "    print('-'*1000)\n",
    "    hit_score_list.append(hit_score)\n",
    "    train_num_list.append(len(temp_train))\n",
    "    building_df_list.append(b_type)\n",
    "    oof_list.append(oof)\n",
    "    avg_hit_rate += hit_score / 60000 * len(temp_train)\n",
    "\n",
    "Result_df = pd.DataFrame({'City' : building_df_list,\n",
    "                        'Train_num' : train_num_list,\n",
    "                        'Hit_score' : hit_score_list})\n",
    "\n",
    "print('Avg hit_score : {}'.format(avg_hit_rate))\n",
    "print('總共花：{} 分'.format((time.time() - begin) / 60))\n",
    "print('現在時間 ： {}'.format(datetime.datetime.today().strftime('%m-%d-%H-%M')))\n",
    "Submission(prediction_df['building_id'], np.expm1(prediction_df['total_price']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train = train[train['building_type'] == 4]\n",
    "temp_test = test[test['building_type'] == 4]\n",
    "'''\n",
    "temp_train = temp_train.join(pd.get_dummies(temp_train['city'], prefix = 'city'))\n",
    "temp_train = temp_train.join(pd.get_dummies(temp_train['parking_way'], prefix = 'parking_way'))\n",
    "temp_test = temp_test.join(pd.get_dummies(temp_test['city'], prefix = 'city'))\n",
    "temp_test = temp_test.join(pd.get_dummies(temp_test['parking_way'], prefix = 'parking_way'))\n",
    "temp_train['miss_parking_area'] = 0\n",
    "temp_train['miss_parking_price'] = 0\n",
    "temp_train.loc[temp_train['parking_area'].isna(), 'miss_parking_area'] = 1\n",
    "temp_train.loc[temp_train['parking_price'].isna(), 'miss_parking_price'] = 1\n",
    "temp_train['parking_price_every_area'] = temp_train['parking_price'] / temp_train['parking_area']\n",
    "temp_train['parking_way'] = temp_train['parking_way'].astype('category')\n",
    "temp_train['parking_area'].fillna(0, inplace =True)\n",
    "temp_train['parking_price'].fillna(0, inplace =True)\n",
    "\n",
    "temp_test['miss_parking_area'] = 0\n",
    "temp_test['miss_parking_price'] = 0\n",
    "temp_test.loc[temp_test['parking_area'].isna(), 'miss_parking_area'] = 1\n",
    "temp_test.loc[temp_test['parking_price'].isna(), 'miss_parking_price'] = 1\n",
    "temp_test['parking_price_every_area'] = temp_test['parking_price'] / temp_test['parking_area']\n",
    "temp_test['parking_way'] = temp_test['parking_way'].astype('category')\n",
    "\n",
    "temp_test['parking_area'].fillna(0, inplace =True)\n",
    "temp_test['parking_price'].fillna(0, inplace =True)\n",
    "'''\n",
    "\n",
    "\n",
    "#temp_train['mean_price'] = temp_train['total_price'] / temp_train['land_area']\n",
    "#temp_test['mean_price'] = 0\n",
    "features = [i for i in temp_train.columns if i not in ['building_id', 'total_price','total_price_log']] \n",
    "#temp_train = temp_train[np.abs(temp_train.land_area-temp_train.land_area.mean()) <= (3*temp_train.land_area.std())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 15.4091957\ttest: 15.4146632\tbest: 15.4146632 (0)\ttotal: 35.6ms\tremaining: 59m 19s\n",
      "1000:\tlearn: 0.5707141\ttest: 0.5775048\tbest: 0.5775048 (1000)\ttotal: 41.7s\tremaining: 1h 8m 47s\n",
      "2000:\tlearn: 0.3764109\ttest: 0.3805691\tbest: 0.3805691 (2000)\ttotal: 1m 19s\tremaining: 1h 4m 31s\n",
      "3000:\tlearn: 0.3630571\ttest: 0.3658852\tbest: 0.3658852 (3000)\ttotal: 1m 56s\tremaining: 1h 2m 43s\n",
      "4000:\tlearn: 0.3563181\ttest: 0.3595061\tbest: 0.3595061 (4000)\ttotal: 2m 33s\tremaining: 1h 1m 33s\n",
      "5000:\tlearn: 0.3535657\ttest: 0.3569532\tbest: 0.3569518 (4997)\ttotal: 3m 10s\tremaining: 1h 26s\n",
      "6000:\tlearn: 0.3514825\ttest: 0.3555156\tbest: 0.3555147 (5992)\ttotal: 3m 45s\tremaining: 58m 52s\n",
      "7000:\tlearn: 0.3471228\ttest: 0.3520452\tbest: 0.3520435 (6990)\ttotal: 4m 23s\tremaining: 58m 19s\n",
      "8000:\tlearn: 0.3437048\ttest: 0.3496065\tbest: 0.3496026 (7993)\ttotal: 4m 57s\tremaining: 56m 57s\n",
      "9000:\tlearn: 0.3422296\ttest: 0.3487260\tbest: 0.3487258 (8998)\ttotal: 5m 30s\tremaining: 55m 36s\n",
      "10000:\tlearn: 0.3407903\ttest: 0.3478550\tbest: 0.3478521 (9977)\ttotal: 6m 2s\tremaining: 54m 25s\n",
      "11000:\tlearn: 0.3380539\ttest: 0.3457628\tbest: 0.3457628 (11000)\ttotal: 6m 36s\tremaining: 53m 26s\n",
      "12000:\tlearn: 0.3368680\ttest: 0.3448743\tbest: 0.3448743 (11999)\ttotal: 7m 10s\tremaining: 52m 35s\n",
      "13000:\tlearn: 0.3364749\ttest: 0.3445964\tbest: 0.3445964 (13000)\ttotal: 7m 46s\tremaining: 51m 58s\n",
      "14000:\tlearn: 0.3360403\ttest: 0.3442812\tbest: 0.3442812 (14000)\ttotal: 8m 29s\tremaining: 52m 6s\n",
      "15000:\tlearn: 0.3355790\ttest: 0.3439385\tbest: 0.3439371 (14985)\ttotal: 9m 9s\tremaining: 51m 51s\n",
      "16000:\tlearn: 0.3352414\ttest: 0.3436831\tbest: 0.3436829 (15990)\ttotal: 9m 49s\tremaining: 51m 32s\n",
      "17000:\tlearn: 0.3348146\ttest: 0.3433723\tbest: 0.3433723 (17000)\ttotal: 10m 23s\tremaining: 50m 42s\n",
      "18000:\tlearn: 0.3338621\ttest: 0.3426434\tbest: 0.3426433 (17998)\ttotal: 10m 57s\tremaining: 49m 55s\n",
      "19000:\tlearn: 0.3332179\ttest: 0.3421031\tbest: 0.3421031 (18999)\ttotal: 11m 35s\tremaining: 49m 24s\n",
      "20000:\tlearn: 0.3326578\ttest: 0.3416226\tbest: 0.3416225 (19980)\ttotal: 12m 13s\tremaining: 48m 55s\n",
      "21000:\tlearn: 0.3322787\ttest: 0.3412857\tbest: 0.3412857 (21000)\ttotal: 12m 53s\tremaining: 48m 27s\n",
      "22000:\tlearn: 0.3315114\ttest: 0.3405938\tbest: 0.3405931 (21998)\ttotal: 13m 31s\tremaining: 47m 57s\n",
      "23000:\tlearn: 0.3302281\ttest: 0.3394645\tbest: 0.3394645 (23000)\ttotal: 14m 10s\tremaining: 47m 28s\n",
      "24000:\tlearn: 0.3298691\ttest: 0.3391010\tbest: 0.3391010 (24000)\ttotal: 14m 48s\tremaining: 46m 53s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.3388168317\n",
      "bestIteration = 24771\n",
      "\n",
      "Shrink model to first 24772 iterations.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CatBoostRegressor' object has no attribute 'best_iteration'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-fc842d7e8772>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcat_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mif_one_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-164af1d27395>\u001b[0m in \u001b[0;36mcat_model\u001b[0;34m(split_num, train, test, features, stratified, if_one_hot)\u001b[0m\n\u001b[1;32m     54\u001b[0m                  \u001b[0muse_best_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                  verbose=1000)\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0moof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CatBoostRegressor' object has no attribute 'best_iteration'"
     ]
    }
   ],
   "source": [
    "cat_model(5, temp_train, temp_test, features= features,if_one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city\n",
       "3     7.381115e+06\n",
       "5     3.099744e+06\n",
       "6     5.417316e+06\n",
       "7     2.881146e+07\n",
       "9     9.084332e+06\n",
       "10    7.625755e+06\n",
       "12    1.013288e+07\n",
       "13    1.203804e+08\n",
       "14    6.643299e+06\n",
       "17    4.539870e+06\n",
       "21    8.812216e+06\n",
       "Name: total_price, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.groupby('city')['total_price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city\n",
       "3     6.672626e+06\n",
       "5     8.017254e+06\n",
       "6     8.301920e+06\n",
       "7     7.814438e+07\n",
       "9     1.485485e+07\n",
       "10    1.266959e+07\n",
       "12    1.357379e+07\n",
       "13    3.975890e+08\n",
       "14    1.349661e+07\n",
       "17    5.696486e+06\n",
       "21    1.686401e+07\n",
       "Name: total_price, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.groupby('city')['total_price'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
